# ğŸšš Dynamic Anomaly Detection & Recommender for Smart Supply Chain

A handsâ€‘on project notebook that detects **operational anomalies** (demand spikes, delayed shipments, sensor faults, inventory drift) and generates **actionable recommendations** (expedite, reroute, reorder, safetyâ€‘stock tweak) to keep the supply chain resilient and efficient.

> File: `Project_Dynamic_Anomaly_Detection_and_Recommender_System_for_Smart_Supply_Chain_Management.ipynb`

---

## ğŸ¯ Objectives

- **Detect anomalies** across orders, inventory, shipments, and IoT sensors in (near) realâ€‘time.
- **Recommend actions** to mitigate risk: reorder, expedite, reroute, supplier switch, staffing alert, etc.
- **Prioritize** incidents by business impact (stockouts avoided, service level protected, cost tradeoffs).

---

## ğŸ§± Approach (high level)

1. **Data ingestion & unification**
   - Merge `orders`, `inventory`, `shipments`, and optional `sensors` time series.
   - Normalize keys: `sku_id`, `location_id`, `timestamp`.
2. **Feature engineering**
   - Rolling stats (mean, std, EWMA), dayâ€‘ofâ€‘week/seasonality, lead/lag, serviceâ€‘level gaps (Onâ€‘Hand â€“ Demand).
3. **Anomaly detection (multiâ€‘method)**
   - **Statistical baselines:** Zâ€‘score / IQR on residuals (actual âˆ’ forecast).
   - **Treeâ€‘based:** Isolation Forest / Local Outlier Factor on window features.
   - **Sequence models (optional):** LSTM/Autoencoder reconstruction error for sensor or demand series.
4. **Forecastâ€‘aware alerts**
   - Fit simple **ARIMA/ETS** (or Prophet) to forecast expected behavior; flag deviations by dynamic thresholds.
5. **Recommendation layer**
   - **Heuristics/Rules:** If `projected_stockout_days < threshold` â‡’ *reorder qty*.
   - **Association/Affinity (optional):** mine coâ€‘movement and substitution to suggest SKU swaps.
   - **Routing/Priority:** suggest expedite/alternate lane when SLA risk > X%.
6. **Scoring & ranking**
   - Business impact score = stockout risk Ã— margin Ã— lead time penalty.
7. **Reporting**
   - Incident table + recommended action with rationale.

---

## ğŸ“¦ Expected data schema (example)

You can adapt names/paths in the first cell of the notebook.

**orders.csv**
- `timestamp` (ISO), `sku_id`, `location_id`, `qty_ordered`

**inventory.csv**
- `timestamp`, `sku_id`, `location_id`, `on_hand`, `on_order`, `safety_stock`

**shipments.csv**
- `timestamp`, `sku_id`, `origin`, `destination` (= `location_id`), `eta_days`, `status`

**sensors.csv` (optional)**
- `timestamp`, `location_id`, `sensor_id`, `value` (e.g., temp, vibration)

> Timestamps should be at a consistent grain (hour/day). The notebook includes resampling helpers.

---

## ğŸ—‚ï¸ Repo structure

```
.
â”œâ”€ Project_Dynamic_Anomaly_Detection_and_Recommender_System_for_Smart_Supply_Chain_Management.ipynb
â”œâ”€ data/
â”‚  â”œâ”€ orders.csv
â”‚  â”œâ”€ inventory.csv
â”‚  â”œâ”€ shipments.csv
â”‚  â””â”€ sensors.csv          # optional
â””â”€ artifacts/              # created by the notebook
   â”œâ”€ anomalies.parquet
   â”œâ”€ recommendations.parquet
   â””â”€ models/              # serialized models (if saved)
```

---

## ğŸš€ Quickstart

1. **Create environment**
   ```bash
   python -m venv .venv && source .venv/bin/activate  # Windows: .venv\Scripts\activate
   pip install -r requirements.txt
   ```
2. **Place data** in `./data/` using the schema above.
3. **Run** the notebook endâ€‘toâ€‘end:  
   ```bash
   jupyter lab  # or jupyter notebook
   ```
4. **Review outputs**
   - `artifacts/anomalies.parquet` â€” each row = detected anomaly with scores & context.
   - `artifacts/recommendations.parquet` â€” action suggestions with confidence & impact.

---

## ğŸ§ª Evaluation & monitoring

- **Anomaly precision/recall** (vs. labeled incidents if available).
- **Alert burden**: alerts/day, % actionable.
- **Business impact**: projected stockouts avoided, SLA adherence, carrying cost deltas.
- **Drift checks**: population stability index (PSI) for key features.

---

## âš™ï¸ Configuration (edit in first cell)

- Paths for `data/` and `artifacts/`
- Time grain (`D`, `H`), lookback windows, and thresholds
- Model toggles: IsolationForest / LOF / ARIMA / LSTMâ€‘AE

---

## ğŸ§° Tech stack

- **Core:** Python 3.8+, pandas, numpy, scikitâ€‘learn
- **Time series:** statsmodels (ARIMA/ETS) or prophet (optional)
- **Anomaly (optional):** pyod
- **Viz:** matplotlib (and optionally seaborn)
- **I/O:** pyarrow / parquet

Minimal `requirements.txt` (adjust to your notebookâ€™s imports):

```
pandas
numpy
scikit-learn
matplotlib
pyarrow
statsmodels
# optional extras used in some variants:
# seaborn
# prophet
# pyod
# tensorflow  # if using LSTM/autoencoder
```

---

## ğŸ“Š What the outputs look like

**anomalies.parquet** (columns)
- `timestamp`, `sku_id`, `location_id`, `metric` (e.g., demand, on_hand, temp)
- `score`, `severity`, `method` (zscore|iforest|arima_resid|lstm_ae)
- `expected`, `actual`, `delta`, `context` (JSON)

**recommendations.parquet** (columns)
- `issue_id`/`anomaly_id`
- `action` (reorder|expedite|reroute|investigate_sensor|adjust_safety_stock)
- `quantity`/`target`/`lane` (as applicable)
- `confidence`, `impact_score`, `notes`

---

## ğŸ›£ï¸ Next steps

- Turn the notebook into a **Streamlit** or **FastAPI** app for interactive triage.
- Add a simple **costâ€‘optimizer** to pick best action under constraints.
- Introduce **multiâ€‘location network effects** (substitution and transshipments).
- Add **Unit tests** and CI for data contracts and thresholds.

---

## ğŸ“œ License

MIT â€” use and modify freely. Replace with your preferred license if needed.

---

## ğŸ™Œ Acknowledgements

- Public retail/supplyâ€‘chain datasets and the openâ€‘source community.
